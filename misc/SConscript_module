#******************************************************************
#
# Institute for System Programming of the Russian Academy of Sciences
# Copyright (C) 2016 ISPRAS
#
#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation, Version 3.
#
# This program is distributed in the hope # that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
# See the GNU General Public License version 3 for more details.
#
#-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=

"""
Build module according to module definition script and partition definition
scripts.
"""

#TODO `ARGUMENTS.get('debug')` change to Variable 'debug'. So debug will be in help

# This script is called from SConscript, when it builds whole module.
#
# The script Import()s variable 'env' contained main environment.
#
# Also, imported invironment should contain following variables:
#
# - 'MODULE_BUILD_DIR' - where module's elf ('pok.elf') should be built.
# (Absolute path).
#
# - 'MODULE_SOURCE_DIR' - where module sources are located.
# (Absolute path).
#
# After that, it executes SConscript located under 'MODULE_SOURCE_DIR'.
# This script is called with variant dir equal to 'MODULE_BUILD_DIR'.
#
# Then, if variable 'MODULE_POST_PROCESS' is set, it is interpreted as
# a function which accepts 'env' argument, and executed.
#
# After that, following variables, described module's components and
# configuraton, are expected to be set:
#
# - 'MODULE_CLEAN_DIRS' - which directories should be clean on `scons -c local`.
# (Absolute path or list of absolute paths; by default equal to MODULE_BUILD_DIR).
#
# - 'MODULE_XML' - xml or other file(s), from which configuration of module
# may be extracted.
# Note: per-partition 'XML' needn't be listed there.
# (Single element or list of element; element could be absolute path, relative (against source dir) or object of type 'File').
#
# - 'MODULE_PARSE_CONFIGURATION' - parser of files listed in 'XML', which should
# return object of type 'chpok_configuration.Configuration'.
# (Function with signature '(sources, env)').
#
# - 'PARTITIONS_NUMBER' - number of partitions in the module.
#
# - 'PARTITION_FILL' - function which will be called for every partition
# environment before call script 'SConscript_partition' for it.
# Index of the partition is passed to that function as the second argument.
# (That is, signature of the function is '(part_env, part_index)').
#
# Executed SConscript may modify/use scons environment variables:
#
# - CFLAGS, CPPPATH and other variables common for "C" compilation.
#   Note, that adjusting of LINKFLAGS is not supported.
#
# - QEMU_FLAGS - flags for qemu for run generated module.
#
# Also, executed SConscript may use methods:
#
# - env.PartitionEnvironment() - create fresh environment, used for
# compile things for partition(user space). E.g., one may use .Object()
# method of that environment and later add its result to
# part_env['PARTITION_SOURCES'] in 'partition_def' scripts (see below).
#
# - env.KernelEnvironment() - create fresh environment, used for
# compile things for kernel. (Note, that these things cannot be compiled
# into the module).
#
#
# After that, for every partition (of total 'PARTITION_NUMBER'):
# 1) environment for it is created,
# 2) 'PARTITION_FILL' method is called
# 3) Script 'SConscript_partition' is executed (that is, method
#    PARTITION_FILL' should set variables required for that script).
#
# After that, target for module's creation are generated.
#
# Return target which builds module's elf.

import os
import shutil

import chpok_configuration
import template_generation
import types_requirements
import jetos_configuration_internal
import memory_definition

import yaml


Import('env')

module_build_dir = env['MODULE_BUILD_DIR']

# Build kernel into given variant_dir.
#
# If variant_dir is not given or None, use 'kernel/' subdirectory
# in the module's build dir.
def BuildKernel(env, variant_dir = None):
    if variant_dir is None:
        variant_dir = module_build_dir+'/kernel'
    kernel_env = env.KernelEnvironment()
    return SConscript(env['JETOS_HOME'] + '/kernel/SConscript',
        exports = 'kernel_env',
        variant_dir = variant_dir,
        duplicate = 0
    )

env.AddMethod(BuildKernel)

# Store value of BOARD_PHYS_SIZE variable before calling module definition script.
board_phys_size_origin = env['BOARD_PHYS_SIZE']

env.SConscript(dirs = env['MODULE_SOURCE_DIR'],
    exports = 'env',
    variant_dir = module_build_dir,
    duplicate = 0)

module_post_process = env.get('MODULE_POST_PROCESS', None)
if module_post_process is not None:
    module_post_process(env)

partition_build_dirs = []
partition_clean_dirs = []
partition_xmls = []
partition_elfs = []
partitions_elf_map = dict()

for part_index in range(env['PARTITIONS_NUMBER']):
    part_env = env.PartitionEnvironment()
    part_env.Append(part_index = part_index)
    env['PARTITION_FILL'](part_env, part_index)

    part_elf = SConscript('SConscript_partition', exports = 'part_env')
    partition_elfs.append(part_elf)
    partitions_elf_map[part_env['PARTITION_NAME']] = part_elf[0].abspath
    partition_build_dirs.append(part_env['PARTITION_BUILD_DIR'])
    partition_clean_dirs.extend(part_env['PARTITION_CLEAN_DIRS'])
    partition_xmls.append(part_env['PARTITION_XML'])

env['PARTITIONS_ELF_MAP'] = partitions_elf_map

# Check if module requests *more physical memory* than board provides.
#
# Note: Module is allowed to request *less physical memory* than board
# provide even in case non-emulated board. In that case
# BOARD_DEPLOY_FUNCTION should use as much memory as requested by
# the module.
board_phys_size_new = env['BOARD_PHYS_SIZE']
if board_phys_size_new > board_phys_size_origin:
    # Requesting more physical memory is allowed only for emulated targets.
    if not env['BOARD_IS_EMULATED']:
        print "ERROR: Module require physical memory of size %x, but board has only %x." % (board_phys_size_new, board_phys_size_origin)
        print "HINT: Extending physical memory is allowed only for emulated boards."
        Exit(1)

if env['BOARD_IS_EMULATED']:
    # Check that physical memory size has alignment suitable for QEMU
    if board_phys_size_new % 2**20:
        print "ERROR: Phisical size of emulated board should be divisible by 1M, but it is %d." % board_phys_size_new

AddMethod(env, template_generation.TemplateRender)

module_xml = env.toAbsPathList(env['MODULE_XML'], env['MODULE_SOURCE_DIR'])

def create_conf_total(target, source, env):
    """
    Create YAML file with "total" configuration.
    TODO: More useful name.
    """
    conf = env['MODULE_PARSE_CONFIGURATION'](source, env)

    treqs = types_requirements.TypesRequirements()
    treqs.load_from_yaml(env['TYPES_REQUIREMENTS_YAML'])

    conf_internal = jetos_configuration_internal.ConfigurationInternal.from_normal(conf, treqs)

    conf_internal.save_to_file(target[0].abspath)

conf_total = env.Command(
    target = os.path.join(module_build_dir, "conf_total.yaml"),
    source = module_xml + partition_xmls,
    action = Action(create_conf_total, '$CONF_TOTAL_COMSTR')
)

env.Depends(conf_total, env['TYPES_REQUIREMENTS_YAML'])


def create_memory_constraints(source, target, env):
    """
    Create memory constraints file from configuration file and
    BOARD_PHYS_SIZE variable (as string).
    """
    conf = jetos_configuration_internal.ConfigurationInternal.load_from_file(source[0].abspath)
    phys_total = int(source[1].get_contents()) # Extracts value from Node.

    md = conf.create_memory_constraints(env, phys_total)

    md.save_to_file(target[0].abspath)

# Generate 'memory_constrains.yaml' for arch processing.
memory_constraints = env.Command(
    target = os.path.join(module_build_dir, "memory_constraints.yaml"),
    source = [conf_total,
        env.Value(str(env['BOARD_PHYS_SIZE'])) # This is Node for value.
    ],
    action = Action(create_memory_constraints, '$MEMORY_CONSTRAINTS_COMSTR')
)

env.Depends(memory_constraints, partition_elfs)

memory_definitions_file = os.path.join(module_build_dir, "memory_definitions.yaml")

env['BOARD_DEPLOYMENT_SOURCES'] = []

env['BOARD_DEPLOY'](env, memory_definitions_file, memory_constraints)


class MemoryBlockInitEntry:
    """
    General initialization entry for memory blocks.
    """
    __slots__ = [
        'init_type', # Type of the initialization, 'ZERO' or 'ELF'.
        'source_id', # Identificator of the source for given initialization type.
        'part_index', # Index of the partition to which memory blocks belong to.
        'memory_blocks', # Non-empty list of memory blocks from the same partition.
    ]
    def __init__(self, init_type, source_id, part_index, memory_blocks):
        self.init_type = init_type
        self.source_id = source_id
        self.part_index = part_index

        if self.init_type == "ELF":
            # For 'ELF' initialization memory blocks should be ordered by vaddr.
            self.memory_blocks = sorted(memory_blocks)
        else:
            # For other initializations order of memory blocks is not required.
            self.memory_blocks = memory_blocks

def create_definitions_for_deployment(source, env):
    """
    Create dictionary with definitions for deployment.c

    Assume source[0] to be conf_total, source[1] - memory_definitions.
    """
    conf = jetos_configuration_internal.ConfigurationInternal.load_from_file(source[0].abspath)
    md = memory_definition.ModuleMemoryDefinition.load_from_file(source[1].abspath)

    # Process memory blocks
    md.memory_block_init_entries = [] # List of MemoryBlockInitEntry

    # First, check shared blocks.
    for memory_block_sharing in md.memory_block_sharings:
        # Only 'MODULE' initialization stage is allowed for shared blocks.
        # All blocks within share should have same initialization politic.

        # First memory block in a sharing list. Note: We know that sharing is not empty.
        first_mb_ref = memory_block_sharing.mb_refs[0]
        first_mb = md.partitions[first_mb_ref.part_index].memory_blocks[first_mb_ref.mb_index]

        # Source for initialization at 'MODULE' stage. Should be common for all blocks in sharing.
        module_init_source = first_mb.init_source

        for memory_block_ref in memory_block_sharing.mb_refs:
            part = md.partitions[memory_block_ref.part_index]
            memory_block =  part.memory_blocks[memory_block_ref.mb_index]

            if memory_block.init_source != module_init_source:
                raise RuntimeError("Memory blocks in sharing use different initialization sources.")

            if module_init_source is not None:
                if memory_block.init_stage != 'MODULE':
                    raise RuntimeError("Only 'MODULE' initialization stage is allowed for shared memory blocks.")
                # Clear initialization of the memory block: We will process it for the whole share.
                memory_block.init_stage = None
                memory_block.init_source = None
        if module_init_source is None:
            continue

        # Process initialization of the share.
        if module_init_source != "ZERO":
            raise RuntimeError("Only 'ZERO' initialization is allowed at 'MODULE' stage.")


        # Initialize via the first memory block in the share.
        mb_init_entry = MemoryBlockInitEntry(
            init_type = module_init_source,
            source_id = 0,
            part_index = first_mb_ref.part_index,
            memory_blocks = [first_mb]
        )
        md.memory_block_init_entries.append(mb_init_entry)

    for part, pmd in zip(conf.partitions, md.partitions):
        # Create initialization records
        pmd.memory_block_init_entries = {'PARTITION': [], 'PARTITION:COLD': []} # Lists of MemoryBlockInitEntry

        elf_blocks = {'MODULE': [], 'PARTITION': [], 'PARTITION:COLD': []}
        zero_blocks = {'MODULE': [], 'PARTITION': [], 'PARTITION:COLD': []}

        for mbd in pmd.memory_blocks:
            if mbd.init_source is None:
                continue
            elif mbd.init_source == "ELF":
                elf_blocks[mbd.init_stage].append(mbd)
            elif mbd.init_source == "ZERO":
                zero_blocks[mbd.init_stage].append(mbd)

        for stage_id in ['PARTITION', 'PARTITION:COLD']:
            if len(elf_blocks[stage_id]) > 0:
                pmd.memory_block_init_entries[stage_id].append(
                    MemoryBlockInitEntry('ELF', 0, part.index, elf_blocks[stage_id])
                )
            if len(zero_blocks[stage_id]) > 0:
                pmd.memory_block_init_entries[stage_id].append(
                    MemoryBlockInitEntry('ZERO', 0, part.index, zero_blocks[stage_id])
                )

        if len(elf_blocks['MODULE']) > 0:
            md.memory_block_init_entries.append(
                MemoryBlockInitEntryModule('ELF', 0, part.index, elf_blocks['MODULE'])
            )
        if len(zero_blocks['MODULE']) > 0:
            md.memory_block_init_entries.append(
                MemoryBlockInitEntryModule('ZERO', 0, part_index, zero_blocks['MODULE'])
            )

    return {'conf': conf, 'memory_definitions': md}

# Generate "deployment.c" for kernel
deployment_kernel = env.TemplateRender(
    target = os.path.join(module_build_dir, "deployment.c"),
    source = conf_total + [memory_definitions_file],
    create_definitions_func = create_definitions_for_deployment,
    template_main = "deployment_kernel",
    template_dir = env['JETOS_HOME'] + "/misc/templates",
    GENERATE_TITLE = template_generation.generate_title_c_no_track
    )


def create_definitions_for_gdb(source, env):
    """
    Create dictionary with definitions for deployment.c

    Assume source[0] to be conf_total.
    """
    conf = jetos_configuration_internal.ConfigurationInternal.load_from_file(source[0].abspath)

    return {'conf': conf,
        'partitions_elf_map': partitions_elf_map,
        'pok_target_file': pok_target_file
    }


gdb_commands_file = os.path.join(module_build_dir, "GDB_commands")

def gdb_commands_action(target, source, env):
    with open(target[0].abspath, 'w') as f:
        f.write('source ' + source[0].path)


if ARGUMENTS.get('debug'):

    if ARGUMENTS.get('debug') not in ['jetos', 'qemu']:
        print("wrong debug value:", ARGUMENTS.get('debug'))
        Exit(1)

    # Generate file with commands for GDB for possible debugging
    gdb_commands_spec = env.TemplateRender(
        target = module_build_dir + "/GDB_commands_" + ARGUMENTS.get('debug'),
        source = conf_total,
        create_definitions_func = create_definitions_for_gdb,
        template_main = "GDB_commands_" + ARGUMENTS.get('debug'),
        template_dir = env['JETOS_HOME'] + "/misc/templates",
        GENERATE_TITLE = template_generation.generate_title_python_no_track
        )
    gdb_commands = env.Command(gdb_commands_file, gdb_commands_spec, Action(gdb_commands_action, '$GDB_COMMANDS_COMSTR'))



kernel_target = env.get('KERNEL_TARGET', None)
# By default, build kernel locally to the example
if kernel_target is None:
    kernel_target = env.BuildKernel()

pok_env = env.KernelEnvironment()

kernel_lo = pok_env.Program(target = module_build_dir+'/kernel.lo',
    source = kernel_target + deployment_kernel + env['BOARD_DEPLOYMENT_SOURCES'])

# there should (perhaps) also be padding to get aligned file size
def merge_partitions(target, source, env):
    with open(str(target[0]), 'wb') as part:
        for s in source:
            with open(str(s), 'rb') as orig_part:
                shutil.copyfileobj(orig_part, part)

def create_sizes_c(target, source, env):
    with open(str(target[0]), 'w') as sizes:
        sizes.write('#include <stdint.h>\n')
        sizes.write('uint32_t pok_elf_sizes[] = {\n')
        for s in source:
            part_size = os.path.getsize(str(s))
            if part_size > pok_env['MAX_PART_SIZE']:
                raise RuntimeError('Partition size must not exceed %d bytes' % pok_env['MAX_PART_SIZE'])
            sizes.write(str(part_size))
            if source.index(s) != len(source) - 1:
                sizes.write(',\n')
        sizes.write('\n};\n')

merge_target = pok_env.Command(target = module_build_dir+'/partitions.bin',
    source = partition_elfs,
    action = Action(merge_partitions, '$MERGE_PARTITIONS_COMSTR'))
pok_env.Depends(merge_target, partition_elfs)

merge_file = merge_target[0].abspath

sizes_c_target = pok_env.Command(target = module_build_dir+'/sizes.c',
    source = partition_elfs,
    action = Action(create_sizes_c, '$SIZES_C_GEN_COMSTR'))
pok_env.Depends(sizes_c_target, partition_elfs)

compile_sizes = pok_env.Command(target = module_build_dir+'/sizes.o',
    source = sizes_c_target,
    action = Action([
        pok_env['CC']+' -c -o $TARGET '+pok_env['CFLAGS']+' $SOURCE',
        pok_env['OBJCOPY']+' --add-section .archive2='+merge_file+' $TARGET'
    ],
    "$SIZES_O_CREATE_COMSTR"
    ))

pok_env.Depends(compile_sizes, merge_target)

pok_elf_env = pok_env.Clone()

ldscript_kernel = pok_env['LDSCRIPT_KERNEL']
# Rewrite LINKFLAGS, as we build '.elf'.
pok_elf_env['LINKFLAGS'] = ' -T ' + ldscript_kernel


pok_target = pok_elf_env.Program(target = module_build_dir+'/pok.elf',
    source = compile_sizes + kernel_lo + [pok_env['LIBGCC']])
pok_env.Depends(pok_target, [ldscript_kernel])

pok_target_file = pok_target[0].abspath

# Make string suitable for use in identifier
def str_to_id(s):
    return s.replace('-', '_')

def unsupported_run_command(target, source, env):
    target_path = target[0].abspath
    cmd_begin_index = target_path.rfind('/') + 1
    cmd_end_index = -4 # Cut '_cmd' suffix
    command = target_path[cmd_begin_index:cmd_end_index]
    bsp_id = str_to_id(env['BSP'])
    command_id = str_to_id(command)
    print "ERROR: Command '" + command + "' is unsupported for board " + env['BSP'] + "."
    print "HINT: You may assign script for this command using 'JETOS_" + command_id + "_" + bsp_id + "' environment variable."
    return 1


def define_run_command(command, qemu_action, depends = []):
    if ARGUMENTS.get('debug'):
        depends.append(gdb_commands)
        if ARGUMENTS.get('debug') == 'jetos':
            qemu_action += ' -serial tcp::8000,server'
        elif ARGUMENTS.get('debug') == 'qemu':
            qemu_action += ' -S -s'

    bsp_id = str_to_id(env['BSP'])
    command_id = str_to_id(command)
    script = os.environ.get('JETOS_' + command_id + "_" + bsp_id, "")
    if script != "":
        action = script + " " + pok_target_file
    elif env['BOARD_IS_EMULATED']:
        action = qemu_action
    else:
        action = unsupported_run_command

    env.Command(command + '_cmd', depends, action)
    env.Alias(command, command + '_cmd')

# Always explicitely set size of memory for QEMU.
env.Append(QEMU_FLAGS = ' -m %dM' % (env['BOARD_PHYS_SIZE'] / 2**20))

env.Append(QEMU_FLAGS = ' -kernel '+pok_target_file)

define_run_command('run',
    '$QEMU $QEMU_FLAGS'
)

define_run_command('run-tap',
    '$QEMU $QEMU_FLAGS  -net nic,model=virtio -net tap,ifname=tap0,script=no,downscript=no'
)

define_run_command('run-tap2',
    '$QEMU $QEMU_FLAGS -net nic,model=virtio,vlan=0 -net nic,model=virtio,vlan=1 -net tap,ifname=tap0,script=no,downscript=no,vlan=0 -net tap,ifname=tap1,script=no,downscript=no,vlan=1'
)

define_run_command('run-tap-rec',
    '$QEMU $QEMU_FLAGS -net nic,model=virtio,vlan=0 -net nic,model=virtio,vlan=1 -net tap,ifname=tap2,script=no,downscript=no,vlan=0 -net tap,ifname=tap3,script=no,downscript=no,vlan=1'
)

define_run_command('run-tap-ne2k',
    '$QEMU $QEMU_FLAGS -net nic,model=ne2k_pci,vlan=0 -net nic,model=ne2k_pci,vlan=1 -net tap,ifname=tap0,script=no,downscript=no,vlan=0, -net tap,ifname=tap1,script=no,downscript=no,vlan=1'
)


def check_gdb_commands_file_exists(target, source, env):
    """
    check if gdb_commands file exists. If not then prints message to help find out the problem.

    TODO: Message probably will be unnecessary when 'debug' argument will became Variable
    """
    if not os.path.exists(gdb_commands_file):
        print("gdb commands file not found. Call scons debug=<'qemu' or 'jetos'> first")
        return 1

env.Command('gdb_cmd', [], action=[
    check_gdb_commands_file_exists,
    '$GDB '+pok_target_file+' -ex "source ' + gdb_commands_file + '"',
    ])
env.Alias('gdb', 'gdb_cmd')

module_clean_dirs = env.get('MODULE_CLEAN_DIRS', module_build_dir)
if type(module_clean_dirs) is not list:
    module_clean_dirs = [module_clean_dirs]
    env['MODULE_CLEAN_DIRS'] = module_clean_dirs


clean_directories = module_clean_dirs + partition_clean_dirs

env.RemoveDirectories('clean_module_cmd', clean_directories)
env.Alias('clean', 'clean_module_cmd')
env.Alias('distclean', 'clean_module_cmd')
env.Clean('#/local', clean_directories)
env.Clean('#/all', clean_directories)

Return('pok_target')

# EOF
